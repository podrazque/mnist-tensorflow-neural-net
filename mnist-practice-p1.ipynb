{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLOXFOT5Q40E"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "iiQkM5ZgQ8r2"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9Jcnb8bQQyd"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/mnist\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/quantum/blob/master/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/quantum/docs/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLObUVeGfTs"
   },
   "source": [
    "This tutorial builds a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TorxE5tnkvb2"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxkQA6oblNqI"
   },
   "source": [
    "Install TensorFlow Quantum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saFHsRDpkvkH"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enZ300Bflq80"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. Load the data\n",
    "\n",
    "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
    "\n",
    "- Loads the raw data from Keras.\n",
    "- Filters the dataset to only 3s and 6s.\n",
    "- Downscales the images so they fit can fit in a quantum computer.\n",
    "- Removes any contradictory examples.\n",
    "- Converts the binary images to Cirq circuits.\n",
    "- Converts the Circ circuits to TensorFlow Quantum circuits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDUdGxn-ojgy"
   },
   "source": [
    "### 1.1 Load the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "Load the MNIST dataset distributed with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9OSExvCojg0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 60000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZpbygdGojg3"
   },
   "source": [
    "Filter the dataset to keep just the 3s and 6s,  remove the other classes. At the same time convert the label, `y`, to boolean: `True` for `3` and `False` for 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOw68cCZojg4"
   },
   "outputs": [],
   "source": [
    "def filter_36(x, y):\n",
    "    keep = (y == 3) | (y == 6)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 3\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-XEU8egGL6q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training examples: 12049\n",
      "Number of filtered test examples: 1968\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = filter_36(x_train, y_train)\n",
    "x_test, y_test = filter_36(x_test, y_test)\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wyiaP0Xojg_"
   },
   "source": [
    "Show the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5STP7MbojhA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1525bbbe0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNS9sVPQojhC"
   },
   "source": [
    "### 1.2 Downscale the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmmtplIFGL6t"
   },
   "source": [
    "An image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbhUdBFWojhE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
    "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMd7zIjGL6x"
   },
   "source": [
    "Again, display the first training example—after resize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIYOtCRIGL6y",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1519b60b8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGeF1_qtojhK"
   },
   "source": [
    "### 1.3 Remove contradictory examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZLkq2yeojhL"
   },
   "source": [
    "From section *3.3 Learning to Distinguish Digits* of <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a>, filter the dataset to remove images that are labeled as belonging to both classes.\n",
    "\n",
    "This is not a standard machine-learning procedure, but is included in the interest of following the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqOPW0C7ojhL"
   },
   "outputs": [],
   "source": [
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "       mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for x,y in zip(xs, ys):\n",
    "      labels = mapping[tuple(x.flatten())]\n",
    "      if len(labels) == 1:\n",
    "          new_x.append(x)\n",
    "          new_y.append(list(labels)[0])\n",
    "      else:\n",
    "          # Throw out images that match more than one label.\n",
    "          pass\n",
    "    \n",
    "    num_3 = sum(1 for value in mapping.values() if True in value)\n",
    "    num_6 = sum(1 for value in mapping.values() if False in value)\n",
    "    num_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of 3s: \", num_3)\n",
    "    print(\"Number of 6s: \", num_6)\n",
    "    print(\"Number of contradictory images: \", num_both)\n",
    "    print()\n",
    "    print(\"Initial number of examples: \", len(xs))\n",
    "    print(\"Remaining non-contradictory examples: \", len(new_x))\n",
    "    \n",
    "    return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMOiJfz_ojhP"
   },
   "source": [
    "The resulting counts do not closely match the reported values, but the exact procedure is not specified.\n",
    "\n",
    "It is also worth noting here that applying filtering contradictory examples at this point does not totally prevent the model from receiving contradictory training examples: the next step binarizes the data which will cause more collisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpnsAssWojhP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 10387\n",
      "Number of 3s:  4961\n",
      "Number of 6s:  5475\n",
      "Number of contradictory images:  49\n",
      "\n",
      "Initial number of examples:  12049\n",
      "Remaining non-contradictory examples:  11520\n"
     ]
    }
   ],
   "source": [
    "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 3. Classical neural network\n",
    "\n",
    "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
    "\n",
    "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZofEHhLGL7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,198,721\n",
      "Trainable params: 1,198,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
    "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiAJl7sZojiU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12049 samples, validate on 1968 samples\n",
      "12049/12049 [==============================] - 12s 976us/sample - loss: 0.0437 - accuracy: 0.9831 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "1968/1968 [==============================] - 0s 195us/sample - loss: 0.0032 - accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5-5BVJaojiZ"
   },
   "source": [
    "The above model has nearly 1.2M parameters. For a more fair comparison, try a 37-parameter model, on the subsampled images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70TOM6r-ojiZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_fair_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_fair_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA_Fx-8gojid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11520 samples, validate on 1968 samples\n",
      "Epoch 1/20\n",
      "11520/11520 - 1s - loss: 0.7262 - accuracy: 0.5013 - val_loss: 0.7059 - val_accuracy: 0.4868\n",
      "Epoch 2/20\n",
      "11520/11520 - 0s - loss: 0.7027 - accuracy: 0.5027 - val_loss: 0.6964 - val_accuracy: 0.4868\n",
      "Epoch 3/20\n",
      "11520/11520 - 0s - loss: 0.6951 - accuracy: 0.5027 - val_loss: 0.6939 - val_accuracy: 0.4868\n",
      "Epoch 4/20\n",
      "11520/11520 - 0s - loss: 0.6933 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.4868\n",
      "Epoch 5/20\n",
      "11520/11520 - 0s - loss: 0.6928 - accuracy: 0.5027 - val_loss: 0.6929 - val_accuracy: 0.4868\n",
      "Epoch 6/20\n",
      "11520/11520 - 0s - loss: 0.6922 - accuracy: 0.5027 - val_loss: 0.6918 - val_accuracy: 0.4868\n",
      "Epoch 7/20\n",
      "11520/11520 - 0s - loss: 0.6876 - accuracy: 0.5027 - val_loss: 0.6750 - val_accuracy: 0.4868\n",
      "Epoch 8/20\n",
      "11520/11520 - 0s - loss: 0.6357 - accuracy: 0.5030 - val_loss: 0.5938 - val_accuracy: 0.4868\n",
      "Epoch 9/20\n",
      "11520/11520 - 0s - loss: 0.5542 - accuracy: 0.5054 - val_loss: 0.5265 - val_accuracy: 0.4914\n",
      "Epoch 10/20\n",
      "11520/11520 - 0s - loss: 0.4948 - accuracy: 0.5058 - val_loss: 0.4786 - val_accuracy: 0.4914\n",
      "Epoch 11/20\n",
      "11520/11520 - 0s - loss: 0.4522 - accuracy: 0.5059 - val_loss: 0.4433 - val_accuracy: 0.4919\n",
      "Epoch 12/20\n",
      "11520/11520 - 0s - loss: 0.4199 - accuracy: 0.8036 - val_loss: 0.4149 - val_accuracy: 0.8039\n",
      "Epoch 13/20\n",
      "11520/11520 - 0s - loss: 0.3938 - accuracy: 0.8386 - val_loss: 0.3907 - val_accuracy: 0.8069\n",
      "Epoch 14/20\n",
      "11520/11520 - 0s - loss: 0.3720 - accuracy: 0.8406 - val_loss: 0.3705 - val_accuracy: 0.8084\n",
      "Epoch 15/20\n",
      "11520/11520 - 0s - loss: 0.3493 - accuracy: 0.8447 - val_loss: 0.3378 - val_accuracy: 0.8084\n",
      "Epoch 16/20\n",
      "11520/11520 - 0s - loss: 0.3000 - accuracy: 0.8483 - val_loss: 0.2881 - val_accuracy: 0.8308\n",
      "Epoch 17/20\n",
      "11520/11520 - 0s - loss: 0.2617 - accuracy: 0.8646 - val_loss: 0.2606 - val_accuracy: 0.8328\n",
      "Epoch 18/20\n",
      "11520/11520 - 0s - loss: 0.2406 - accuracy: 0.8652 - val_loss: 0.2456 - val_accuracy: 0.8328\n",
      "Epoch 19/20\n",
      "11520/11520 - 0s - loss: 0.2281 - accuracy: 0.8654 - val_loss: 0.2366 - val_accuracy: 0.8328\n",
      "Epoch 20/20\n",
      "11520/11520 - 0s - loss: 0.2203 - accuracy: 0.8656 - val_loss: 0.2306 - val_accuracy: 0.8328\n",
      "1968/1968 [==============================] - 0s 30us/sample - loss: 0.2306 - accuracy: 0.8328\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_bin,\n",
    "          y_train_nocon,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 4. Comparison\n",
    "\n",
    "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOMeN7pMGL7P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14fa84cf8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANeklEQVR4nO3cf6xfd13H8edr7QZR9yPaqy5tt5bYoc3kx7hUIk5HKEm3xDYGIq3BgVloiFbNQJIRSVlKlMCMRrCIRZeNqSsTIrmRkmpgywgy7K37wbql5FpxbUXWjWUGAUv17R/31H13d+/9nrbf9rafPh/JTb7nnM8959Pm7LnT8/2eb6oKSdK574KFnoAkaTQMuiQ1wqBLUiMMuiQ1wqBLUiMWL9SBlyxZUitWrFiow0vSOWnv3r1PVdXYbNsWLOgrVqxgcnJyoQ4vSeekJP821zZvuUhSIwy6JDXCoEtSIwy6JDXCoEtSI4YGPcntSZ5M8ugc25Pkw0mmkjyS5JrRT1OSNEyfK/Q7gHXzbL8eWNX9bAb+9NSnJUk6UUODXlX3A9+aZ8gG4BM17QHgsiSXj2qCkqR+RnEPfSlwcGD5ULdOknQGndEnRZNsZvq2DFdcccUp7+9V7/7EKe9D7dl7240LPQVpQYziCv0wsHxgeVm37gWqakdVjVfV+NjYrF9FIEk6SaMI+gRwY/dpl9cAz1bVN0awX0nSCRh6yyXJ3cB1wJIkh4D3ARcCVNXHgF3ADcAU8B3g107XZCVJcxsa9KraNGR7Ab8xshlJkk6KT4pKUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMWL/QEpBY9se2nF3oKOgtdsfWrp3X/XqFLUiMMuiQ1wqBLUiN6BT3JuiT7k0wluWWW7VckuTfJg0keSXLD6KcqSZrP0KAnWQRsB64HVgObkqyeMey9wD1V9UpgI/DRUU9UkjS/Plfoa4CpqjpQVUeBncCGGWMKuKR7fSnw76OboiSpjz5BXwocHFg+1K0bdCvwliSHgF3Ab862oySbk0wmmTxy5MhJTFeSNJdRvSm6CbijqpYBNwB3JXnBvqtqR1WNV9X42NjYiA4tSYJ+QT8MLB9YXtatG3QTcA9AVX0ZeDGwZBQTlCT10yfoe4BVSVYmuYjpNz0nZox5Ang9QJKfYjro3lORpDNoaNCr6hiwBdgNPM70p1n2JdmWZH037F3A25M8DNwNvK2q6nRNWpL0Qr2+y6WqdjH9Zufguq0Drx8DXjvaqUmSToRPikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDWiV9CTrEuyP8lUklvmGPPLSR5Lsi/JX492mpKkYRYPG5BkEbAdeANwCNiTZKKqHhsYswp4D/DaqnomyY+erglLkmbX5wp9DTBVVQeq6iiwE9gwY8zbge1V9QxAVT052mlKkobpE/SlwMGB5UPdukFXAVcl+VKSB5Ksm21HSTYnmUwyeeTIkZObsSRpVqN6U3QxsAq4DtgEfDzJZTMHVdWOqhqvqvGxsbERHVqSBP2CfhhYPrC8rFs36BAwUVXfr6p/Bb7GdOAlSWdIn6DvAVYlWZnkImAjMDFjzGeYvjonyRKmb8EcGOE8JUlDDA16VR0DtgC7gceBe6pqX5JtSdZ3w3YDTyd5DLgXeHdVPX26Ji1JeqGhH1sEqKpdwK4Z67YOvC7gnd2PJGkB+KSoJDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDWiV9CTrEuyP8lUklvmGffGJJVkfHRTlCT1MTToSRYB24HrgdXApiSrZxl3MfDbwFdGPUlJ0nB9rtDXAFNVdaCqjgI7gQ2zjHs/8EHgeyOcnySppz5BXwocHFg+1K37f0muAZZX1Wfn21GSzUkmk0weOXLkhCcrSZrbKb8pmuQC4A+Bdw0bW1U7qmq8qsbHxsZO9dCSpAF9gn4YWD6wvKxbd9zFwNXAfUm+DrwGmPCNUUk6s/oEfQ+wKsnKJBcBG4GJ4xur6tmqWlJVK6pqBfAAsL6qJk/LjCVJsxoa9Ko6BmwBdgOPA/dU1b4k25KsP90TlCT1s7jPoKraBeyasW7rHGOvO/VpSZJOlE+KSlIjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNaJX0JOsS7I/yVSSW2bZ/s4kjyV5JMnnk1w5+qlKkuYzNOhJFgHbgeuB1cCmJKtnDHsQGK+qlwGfAj406olKkubX5wp9DTBVVQeq6iiwE9gwOKCq7q2q73SLDwDLRjtNSdIwfYK+FDg4sHyoWzeXm4DPzbYhyeYkk0kmjxw50n+WkqShRvqmaJK3AOPAbbNtr6odVTVeVeNjY2OjPLQknfcW9xhzGFg+sLysW/c8SdYCvwv8QlX992imJ0nqq88V+h5gVZKVSS4CNgITgwOSvBL4M2B9VT05+mlKkoYZGvSqOgZsAXYDjwP3VNW+JNuSrO+G3Qb8EPA3SR5KMjHH7iRJp0mfWy5U1S5g14x1Wwderx3xvCRJJ8gnRSWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEb2CnmRdkv1JppLcMsv2FyX5ZLf9K0lWjHqikqT5DQ16kkXAduB6YDWwKcnqGcNuAp6pqp8A/gj44KgnKkmaX58r9DXAVFUdqKqjwE5gw4wxG4A7u9efAl6fJKObpiRpmMU9xiwFDg4sHwJ+Zq4xVXUsybPAjwBPDQ5KshnY3C1+O8n+k5m0ZrWEGX/f56v8wVsXegp6Ps/N4943kuvcK+fa0CfoI1NVO4AdZ/KY54skk1U1vtDzkGby3Dxz+txyOQwsH1he1q2bdUySxcClwNOjmKAkqZ8+Qd8DrEqyMslFwEZgYsaYCeD4v3PfBHyhqmp005QkDTP0lkt3T3wLsBtYBNxeVfuSbAMmq2oC+AvgriRTwLeYjr7OLG9l6WzluXmGxAtpSWqDT4pKUiMMuiQ1wqCPSJIfT7Izyb8k2ZtkV5KrkqxI8ugIj7MtydqT+L1e80jyW0keT/JXQ8Z9+0T2q4VzPp2bScaTfPhE59CKM/o59FZ1T8X+LXBnVW3s1r0c+DGe/1DWKauqraPc3yx+HVhbVYdO83F0Bpxv52ZVTQKTM9cnWVxVx07n5M4GXqGPxuuA71fVx46vqKqHq+qLg4O6K5EvJvnn7udnu/WXJ7k/yUNJHk1ybZJFSe7olr+a5OZu7B1J3tS9fnWSf0zycJJ/SnLxXMfoI8nHgJcAn0tyc5Jbk/zOwPZH/eK1c06r5+aaJF9O8mB3nJd2465L8nfd61uT3JXkS8Bdp/bXeG7wCn00rgb29hj3JPCGqvpeklXA3cA48CvA7qr6vUx/GdoPAK8AllbV1QBJLhvcUfdMwCeBN1fVniSXAN+d5xhDVdU7kqwDXldVTyW5tc/v6azW6rl5CXBt97HqtcDvA2+c5VdXAz9XVd/tc5xznUE/sy4E/iTJK4D/Aa7q1u8Bbk9yIfCZqnooyQHgJUk+AnwW+PsZ+3op8I2q2gNQVf8JkOQH5ziGNJ9z7dy8FLiz+x9DdfOfzcT5EnPwlsuo7ANe1WPczcA3gZczfWVyEUBV3Q/8PNNfoXBHkhur6plu3H3AO4A/7zmXWY9xko7x/HPkxaewLy2MVs/N9wP3dv9K+EXmPjf/6xSOcc4x6KPxBeBFmf42SQCSvCzJtTPGXcr0lcv/Ar/K9JO3JLkS+GZVfZzp/ziuSbIEuKCqPg28F7hmxr72A5cneXW3j4vz3PfovOAYg5IsTfL5Hn+urx8/bpJrgJU9fkdnl1bPzUt57jul3tZj/HnBoI9A9701vwSszfRHw/YBHwD+Y8bQjwJvTfIw8JM8d/VwHfBwkgeBNwN/zPRXEt+X5CHgL4H3zDjm0W7sR7r9/QPTVylzHWPQ5UxffQ/zaeCHuz/PFuBrPX5HZ5GGz80PAR/o5uWt446P/p+HMv3dPE9038MjnTU8N0+NQZekRnjLRZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRH/B9mQvW7C99HSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_accuracy = cnn_results[1]\n",
    "fair_nn_accuracy = fair_nn_results[1]\n",
    "\n",
    "sns.barplot([\"Classical, full\", \"Classical, fair\"],\n",
    "            [cnn_accuracy, fair_nn_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
